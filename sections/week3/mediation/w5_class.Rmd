## In-Class Exercises

```{r, echo = FALSE}
library(foreign)
library(lavaan)
library(dplyr)

knitr::opts_chunk$set(fig.align = "center", out.width = "100%")

seData <- read.spss(paste0(dataDir, "SelfEsteem.sav"), to.data.frame = TRUE)
```

In This practical, we will continue with our mediation analysis of the data 
provided by the *SelfEsteem.sav* file.

---

###

Load the *SelfEsteem.sav* data.

<details>
  <summary>Click for explanation</summary>

```{r, eval = FALSE}
library(foreign)
seData <- read.spss("SelfEsteem.sav", to.data.frame = TRUE)
```

</details>

---

To begin this practical, recall the path model that we estimated for the 
[At-Home Exercises](at-home-exercises-3.html).

```{r fullDiagram, fig.cap = "Full Model", echo = FALSE}
knitr::include_graphics(paste0(imageDir, "week5_full_model.png"))
#![](images/week5_home_full_model.png)
```

Further, recall the research questions for our analysis.

1. Better peer relationships will promote higher self-esteem via a three-step 
indirect process.
    a. Better peer relationships will increase empathy levels.
    a. Higher empathy will increase prosocial behavior and decrease aggressive 
    behavior.
    a. More prosocial behaviors and less aggressive behavior will both produce 
    higher self-esteem.
1. Better relationships with parents directly increase self-esteem.

Clearly, we have estimated more paths than we need to directly assess the 
hypotheses. We could still calculate the relevant direct/indirect/total effects 
from a simpler model.

---

### {#diagram}

Draw a path diagram for the simplest model that you could use to define the 
effects implied by the above hypotheses.

- For the purposes of testing the final hypothesis, you may treat *direct* and 
*total* effects as synonymous.
- Keep the covariances between `ParAtt` and `PeerAtt` and between `ProSoc` and 
`Aggr` in the model.

<details>
  <summary>Click for explanation</summary>

```{r resDiagram, fig.cap = "Restricted Model", echo = FALSE}
knitr::include_graphics(paste0(imageDir, "week5_res_model.png"))
#![](images/week5_home_res_model.png)
```

</details>

---

### {#resMod}

Define the **lavaan** model syntax for the path model you diagrammed in 
\@ref(diagram).

- Label any relevant paths
- Specify any relevant indirect effects as defined parameters. 
- Save the syntax string as an object in your environment.

<details>
  <summary>Click for explanation</summary>

```{r}
resMod <- '
## Equation for outcome:
SelfEst ~ y_m21 * ProSoc + y_m22 * Aggr + ParAtt

## Equations for stage 2 mediators:
ProSoc ~ m21_m1 * Emp
Aggr ~ m22_m1 * Emp

## Equation for stage 1 mediator:
Emp ~ m1_x2 * PeerAtt

## Covariances:
ProSoc ~~ Aggr
ParAtt ~~ PeerAtt

## Indirect effects:
ie_pro := m1_x2 * m21_m1 * y_m21
ie_agg := m1_x2 * m22_m1 * y_m22
'
```

</details>

---

### {#estimateRes}

Estimate the model defined in \@ref(resMod) using 1000 bootstrap samples.

- Other than the `se` and `bootstrap` options, use the defaults.
- How does the model fit?
- Is the hypothesized total/direct effect from `ParAtt` to `SelfEst` significant?
- Are the hypothesized IEs significant according to the one-tailed 95% bootstrap CIs?

<details>
  <summary>Click for explanation</summary>

```{r res_boot_estimate, cache = TRUE}
## Set a seed to get replicable bootstrap samples:
set.seed(235711)

## Estimate the restricted model with bootstrapping:
out_res <- sem(resMod, data = seData, se = "bootstrap", bootstrap = 1000)

## Summarize the model:
summary(out_res, fit.measures = TRUE)

## Compute CIs:
parameterEstimates(out_res, ci = TRUE, level = 0.9)
```

```{r, include = FALSE}
tmp <- summary(out_res)$pe
par <- tmp %>% filter(op == "~", rhs == "ParAtt")

tmp <- parameterEstimates(out_res, ci = TRUE, level = 0.9)
pro <- tmp %>% filter(label == "ie_pro")
agg <- tmp %>% filter(label == "ie_agg")
```

- The fit of the model is marginal. The $\chi^2$ is pretty small, and the CFI 
looks good, but the TLI is below the threshold of acceptable fit. The RMSEA and 
SRMR are toward the upper end of the range for "acceptable" fit.

- Yes, the direct effect of *Parent Attachment* on *Self Esteem*  is significant 
($\beta = `r par$est %>% round(3)`$, 
$Z = `r par$z %>% round(2)`$,
$p < 0.001$).

- The IE of *Peer Attachment* on *Self Esteem* through *Empathy* and *Prosocial 
Behavior* is significant ($\hat{\textit{IE}} = `r pro$est %>% round(3)`$, 
$95\% ~ CI = [`r pro$ci.lower %>% round(3)`; \infty]$), as is the analogous IE 
through *Aggressive Behavior* ($\hat{\textit{IE}} = `r agg$est %>% round(3)`$, 
$95\% ~ CI = [-\infty; `r agg$ci.upper %>% round(3)`]$).

</details>

---

###

Re-estimate the model from \@ref(boot) in the At-Home Exercises.

- Use B = 1000 bootstrap samples.
- Other than the `se` and `bootstrap` options, use the defaults.
- Does this model give the same answers (vis-Ã -vis the hypotheses) as the 
restricted model from \@ref(estimateRes)?

<details>
  <summary>Click for explanation</summary>

```{r full_boot_estimate, cache = TRUE}
## Define the model syntax:
fullMod <- '
## Equation for outcome:
SelfEst ~ y_m21 * ProSoc + y_m22 * Aggr + Emp + ParAtt + PeerAtt

## Equations for stage 2 mediators:
ProSoc ~ m21_x2 * PeerAtt + ParAtt + m21_m1 * Emp
Aggr ~ m22_x2 * PeerAtt + ParAtt + m22_m1 * Emp

## Equation for stage 1 mediator:
Emp ~ ParAtt + m1_x2 * PeerAtt

## Covariances:
ProSoc ~~ Aggr
ParAtt ~~ PeerAtt

## Indirect effects:
ie_pro := m1_x2 * m21_m1 * y_m21
ie_agg := m1_x2 * m22_m1 * y_m22
'
## Set a seed to get replicable bootstrap samples:
set.seed(235711)

## Estimate the model with bootstrapping:
out_full <- sem(fullMod, data = seData, se = "bootstrap", bootstrap = 1000)

## Summarize the model:
summary(out_full)
parameterEstimates(out_full, ci = TRUE, level = 0.9)
```

Although the estimates differ somewhat, the inferential conclusions are 
more-or-less the same whether we estimate the effects with the full or the 
restricted model.

- The meaning of these effects are not identical though.
- We are partialing out the effects of more variables in the full model.

</details>

---

If you found that the inferential conclusions were the same in the full and 
restricted models, considerations of parsimony may tempt you to base your 
conclusions on the restricted model. However, to do so at this point would be 
premature.

We must first show that the restricted model is an equally good representation 
of the data. The restricted model is nested within the full model, so we can use
a $\Delta \chi^2$ test to evaluate the loss of fit.

---

###

Conduct a $\Delta \chi^2$ test to check if the restricted model still fits 
sufficiently well.

- What do you conclude?
- Do you notice anything about the relation between the $\Delta \chi^2$ in this 
test and the $\chi^2$ model fit statistic from \@ref(estimateRes)?

*Hint:* You can use the `anova()` function to conduct a $\Delta \chi^2$ test 
between two fitted **lavaan** objects.

<details>
  <summary>Click for explanation</summary>

```{r}
anova(out_full, out_res)
```

- The $\Delta \chi^2$ is significant, so we should not prefer the restricted 
model. Constraining the full model has produced too much loss of fit.
- The $\Delta \chi^2$ (and it's associated degrees of freedom and p-value) is
identical to the model fit statistic from \@ref(estimateRes). Of course, we should
not find this surprising. Since the full model is saturated, it has $\chi^2 = 0$.
So, our $\Delta \chi^2$ statistic was computed by subtracting zero from the $\chi^2$
for the restricted model. Hence, we didn't really need to do this test; we 
already had the answer.

</details>

---

Recall the four different flavors of effect that we can define in a multiple 
mediation model.

1. Total effect
1. Direct effect
1. Specific indirect effect
1. Total indirect effect

Take note of the following points.

- If we have multiple inputs and/or outcomes, we can each pair of X and Y will
be linked through a set of these four effects.
- If any of the multiple mediators are arranged serially in the process, these 
four flavors of effect can connect an input to a mediator, connect a mediator 
to an outcome, or connect two mediators.  

So, we can define many different effects when working with complicated process 
models.

---

###

List all possible effects (i.e., direct, total, [specific/total] indirect) that 
we can define based on the full model represented in Figure \@ref(fig:fullDiagram).

- Do not include the paths that attach variables that are adjacent in the process 
(e.g., a and b paths).

<details>
  <summary>Click for explanation</summary>

***Three-Step Specific Indirect Effects***

1. Y_M21_M1_X1 = *Parent Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Prosocial Behavior* $\rightarrow$ *Self Esteem*
1. Y_M22_M1_X1 = *Parent Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Aggressive Behavior* $\rightarrow$ *Self Esteem*
1. Y_M21_M1_X2 = *Peer Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Prosocial Behavior* $\rightarrow$ *Self Esteem*
1. Y_M22_M1_X2 = *Peer Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Aggressive Behavior* $\rightarrow$ *Self Esteem*

***Two-Step Specific Indirect Effects***

1. Y_M1_X1 = *Parent Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Self Esteem*

1. Y_M21_X1 = *Parent Attachment* $\rightarrow$ *Prosocial Behavior* 
$\rightarrow$ *Self Esteem*
1. M21_M1_X1 = *Parent Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Prosocial Behavior*
1. Y_M21_M1 = *Empathy* $\rightarrow$ *Prosocial Behavior* $\rightarrow$ 
*Self Esteem*

1. Y_M22_X1 = *Parent Attachment* $\rightarrow$ *Aggressive Behavior* 
$\rightarrow$ *Self Esteem*
1. M22_M1_X1 = *Parent Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Aggressive Behavior*
1. Y_M22_M1 = *Empathy* $\rightarrow$ *Aggressive Behavior* $\rightarrow$ 
*Self Esteem*

1. Y_M1_X2 = *Peer Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Self Esteem*

1. Y_M21_X2 = *Peer Attachment* $\rightarrow$ *Prosocial Behavior* $\rightarrow$ 
*Self Esteem*
1. M21_M1_X2 = *Peer Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Prosocial Behavior*
1. Y_M21_M1 = *Empathy* $\rightarrow$ *Prosocial Behavior* $\rightarrow$ 
*Self Esteem*

1. Y_M22_X2 = *Peer Attachment* $\rightarrow$ *Aggressive Behavior* 
$\rightarrow$ *Self Esteem*
1. M22_M1_X2 = *Peer Attachment* $\rightarrow$ *Empathy* $\rightarrow$ 
*Aggressive Behavior*
1. Y_M22_M1 = *Empathy* $\rightarrow$ *Aggressive Behavior* $\rightarrow$ *Self 
Esteem*

***Total Indirect Effects***

1. IE_Y_X1 = Y_M21_M1_X1 + Y_M22_M1_X1 + Y_M1_X1 + Y_M21_X1 + Y_M22_X1
1. IE_Y_X2 = Y_M21_M1_X2 + Y_M22_M1_X2 + Y_M1_X2 + Y_M21_X2 + Y_M22_X2

1. IE_Y_M1 = Y_M21_M1 + Y_M22_M1

***Direct Effects***

1. DE_Y_X1 = *Parent Attachment* $\rightarrow$ *Self Esteem*
1. DE_M21_X1 = *Parent Attachment* $\rightarrow$ *Prosocial Behavior*
1. DE_M22_X1 = *Parent Attachment* $\rightarrow$ *Aggressive Behavior*

1. DE_Y_X2 = *Peer Attachment* $\rightarrow$ *Self Esteem*
1. DE_M21_X2 = *Peer Attachment* $\rightarrow$ *Prosocial Behavior*
1. DE_M22_X2 = *Peer Attachment* $\rightarrow$ *Aggressive Behavior*

1. DE_Y_M1 = *Empathy* $\rightarrow$ *Self Esteem*

***Total Effects***

1. TE_Y_X1 = IE_Y_X1 + DE_Y_X1
1. TE_Y_X2 = IE_Y_X2 + DE_Y_X2

1. TE_Y_M1 = IE_Y_M1 + DE_Y_M1

1. TE_M21_X1 = M21_M1_X1 + DE_M21_X1
1. TE_M21_X2 = M21_M1_X2 + DE_M21_X2

1. TE_M22_X1 = M22_M1_X1 + DE_M22_X1
1. TE_M22_X2 = M22_M1_X2 + DE_M22_X2

</details>

---

### {#ieMod}

Modify the model syntax for the full model to define all possible specific and 
total indirect effects between *Parent Attachment* and *Self Esteem* and between 
*Peer Attachment* and *Self Esteem*.

<details>
  <summary>Click for explanation</summary>

```{r}
mod <- '
## Equation for outcome:
SelfEst ~ y_m21 * ProSoc + 
          y_m22 * Aggr   + 
          y_m1  * Emp    + 
                  ParAtt + 
                  PeerAtt

## Equations for stage 2 mediators:
ProSoc ~ m21_x2 * PeerAtt + 
         m21_x1 * ParAtt  + 
         m21_m1 * Emp
Aggr ~ m22_x2 * PeerAtt + 
       m22_x1 * ParAtt  +
       m22_m1 * Emp

## Equation for stage 1 mediator:
Emp ~ m1_x1 * ParAtt + m1_x2 * PeerAtt

## Covariances:
ProSoc ~~ Aggr
ParAtt ~~ PeerAtt

## Specific indirect effects:
ie_m21_m1_x1 := m1_x1 * m21_m1 * y_m21
ie_m22_m1_x1 := m1_x1 * m22_m1 * y_m22

ie_m21_m1_x2 := m1_x2 * m21_m1 * y_m21
ie_m22_m1_x2 := m1_x2 * m22_m1 * y_m22

ie_m21_x2 := m21_x2 * y_m21
ie_m22_x2 := m22_x2 * y_m22

ie_m21_x1 := m21_x1 * y_m21
ie_m22_x1 := m22_x1 * y_m22

ie_m1_x1 := m1_x1 * y_m1
ie_m1_x2 := m1_x2 * y_m1

## Total indirect effects:
y_x1 := ie_m21_m1_x1 + ie_m22_m1_x1 + ie_m21_x1 + ie_m22_x1 + ie_m1_x1
y_x2 := ie_m21_m1_x2 + ie_m22_m1_x2 + ie_m21_x2 + ie_m22_x2 + ie_m1_x2
'
```

</details>

---

###

Use `lavaan::sem()` to estimate the model from \@ref(ieMod).

- Use B = 1000 bootstrap samples.
- Other than the `se` and `bootstrap` options, use the defaults.
- Which specific and total indirect effects are significant according to the 
bootstrapped CIs?

<details>
  <summary>Click for explanation</summary>

```{r ie_boot, cache = TRUE}
## Load the dplyr package to help parse the results:
library(dplyr)

## Set a seed to get replicable bootstrap samples:
set.seed(235711)

## Estimate the model with bootstrapping:
out <- sem(mod, data = seData, se = "bootstrap", bootstrap = 1000)

## Summarize the model:
summary(out)

parameterEstimates(out, ci = TRUE, level = 0.9) %>% 
  filter(op == ":=") %>% 
  select(label, est, ci.lower, ci.upper)
```

```{r, include = FALSE}
tmp <- parameterEstimates(out, ci = TRUE, level = 0.9)

tmp1 <- tmp %>% filter(label == "ie_m21_m1_x2")
tmp2 <- tmp %>% filter(label == "ie_m22_m1_x2")
tmp3 <- tmp %>% filter(label == "ie_m21_x1")
tmp4 <- tmp %>% filter(label == "y_x1")
tmp5 <- tmp %>% filter(label == "y_x2")
```

- Both three-step IEs from *Peer Attachment* to *Self Esteem* are significant 
(*Prosocial Behavior*: 
$\hat{\textit{IE}} = `r tmp1$est %>% round(3)`$, 
$95\% ~ CI = [`r tmp1$ci.lower %>% round(3)`; \infty]$
; *Aggressive Behavior*:
$\hat{\textit{IE}} = `r tmp2$est %>% round(3)`$, 
$95\% ~ CI = [-\infty; `r tmp2$ci.upper %>% round(3)`]$).
- The two-step IE from *Parent Attachment* to *Self Esteem* through *Prosocial 
Behavior* is significant 
($\hat{\textit{IE}} = `r tmp3$est %>% round(3)`$, 
$95\% ~ CI = [`r tmp3$ci.lower %>% round(3)`; \infty]$).
- The total IE from *Parent Attachment* to *Self Esteem* is significant 
($\hat{\textit{IE}} = `r tmp4$est %>% round(3)`$, 
$95\% ~ CI = [`r tmp4$ci.lower %>% round(3)`; \infty]$).

Interestingly, the total IE from *Peer Attachment* to *Self Esteem* is not 
significant even though two of the underlying specific indirect effects are 
significant. Can you think of an explanation for this (apparent) inconsistency?

</details>

---

If we want to compare the size of indirect effects (specific or total), we only 
need to consider the scaling of the input and outcome variables. The indirect
effect is interpreted as the expected change in Y for each unit of change in X
that is transmitted through M; the scaling of the mediators does not enter into
the interpretation.

---

### {#qualComp}

In terms of a qualitative comparison of effect sizes, which of each of the 
following pairs of IEs is larger?

- The two three-step IEs from *Peer Attachment* to *Self Esteem*.
- The total IEs from *Parent Attachment* vs. *Peer Attachment* to *Self Esteem*.

*Note:* Both *Parent Attachment* and *Peer Attachment* have the same scale.

<details>
  <summary>Click for explanation</summary>

- The specific IE through *Prosocial Behavior* (`r tmp1$est %>% round(3)`) is 
stronger than the specific IE through *Aggressive Behavior* 
(`r tmp2$est %>% round(3)`).
- The total IE for *Parent Attachment* (`r tmp4$est %>% round(3)`) is stronger 
than the total IE for *Peer Attachment* (`r tmp5$est %>% round(3)`).

</details>

---

If we want to conduct a formal statistical test for these comparisons, we can
define a new parameter that quantifies the difference we wish to evaluate and 
use bootstrapping to estimate a sampling distribution for this defined parameter. 
We then make the inferences exactly as we did for the IEs.

---

### {#testMod}

Modify the model syntax from \@ref(ieMod) to include parameters that quantify
the differences need to test the comparisons in \@ref(qualComp).

<details>
  <summary>Click for explanation</summary>

Rather than copying the entire syntax string, I'll use the `paste()` function to
add only the two new lines to the existing syntax.

```{r}
## Modify the model syntax:
mod <- paste(mod, 
             'sie_diff := ie_m21_m1_x2 + ie_m22_m1_x2',
             'tie_diff := y_x1 - y_x2',
             sep = "\n")

## Check the result:
cat(mod)
```

When defining the difference between the two specific indirect effects, 
`sie_diff`, we *add* the effects because the second specific IE (through 
*Aggressive Behavior*) is negative. We want to test the difference in magnitude, 
not the difference between the signed estimates. So, we need to define the 
difference in terms of the absolute values of the specific indirect effects.

</details>

---

###

Use `lavaan::sem()` to estimate the model you defined in \@ref(testMod).

- Use B = 1000 bootstrap samples.
- Other than the `se` and `bootstrap` options, use the defaults.
- Are the tested specific and total indirect effects are significant different
according to the bootstrapped CIs?

<details>
  <summary>Click for explanation</summary>

Note that we now need to use two-tailed tests again, since we do not have any 
particular reason to expect that one effect will be stronger than the other.

```{r test_boot, cache = TRUE}
## Set a seed to get replicable bootstrap samples:
set.seed(235711)

## Estimate the model with bootstrapping:
out <- sem(mod, data = seData, se = "bootstrap", bootstrap = 1000)

## Summarize the model:
summary(out)

parameterEstimates(out, ci = TRUE) %>% 
  filter(label %in% c("sie_diff", "tie_diff")) %>% 
  select(label, est, ci.lower, ci.upper)
```

Neither the two three-step specific indirect effects from *Peer Attachment* to
*Self Esteem* nor the two total effects from the inputs to *Self Esteem* are 
significantly different.

</details>

---

###

Reconsider the answers you gave to the research questions after the At-Home 
Exercise analyses.

- Do the new results you've found here change your conclusions?
- What are your conclusions vis-Ã -vis the stated hypotheses?

<details>
  <summary>Click for explanation</summary>

The new results further support the hypotheses regarding the indirect effect of 
*Peer Attachment* on *Self Esteem*.

- Both three-step specific indirect effects were significant.
- None of the other potential specific indirect effects from *Peer Attachment*
to *Self Esteem* was significant.
- As far as our model can tell, it appears that *Peer Attachment* really does 
influence *Self Esteem* primarily through the two hypothesized three-step
IEs.

The new results provide evidence against the hypothesized stand-alone direct
effect of *Parent Attachment* on *Self Esteem*.

- Although the hypothesized direct effect is significant, so is the total
indirect effect and the specific indirect effect through *Prosocial Behavior*.
- Our model suggests that *Parent Attachment* influences *Self Esteem* both
directly and indirectly.

</details>

---

End of In-Class Exercises

---
